{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset allocine_dataset (/root/.cache/huggingface/datasets/allocine_dataset/allocine/1.0.0/bbee2ebb45a067891973b91ebdd40a93598d1e2dd5710b6714cdc2cd81d0ed65)\n",
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import torch\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from config import *\n",
    "from datasets import load_dataset\n",
    "from utils import one_inference_fn\n",
    "import transformers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_dataset(\"allocine\")\n",
    "#dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = dataset['test']['review']\n",
    "#label = dataset['test']['label']\n",
    "#df = pd.DataFrame()\n",
    "#df['messages'] = data\n",
    "#df['labels'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#df['ids'] = df['messages'].apply(lambda x: str(uuid.uuid4()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_parquet('cine_opke_oluwa_Jan-21-2021.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = transformers.CamembertForSequenceClassification.from_pretrained(\"camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = list(model.named_parameters())\n",
    "#no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', \n",
    "#            'classifier.dense.weight', 'classifier.dense.bias', \n",
    "#            'classifier.out_proj.weight', 'classifier.out_proj.bias'] # We don't want any decay for them\n",
    "\n",
    "\n",
    "#[p for n, p in parameters if not any(nd in n for nd in no_decay)]\n",
    "#[n for n, p in parameters if any(nd in n for nd in no_decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXperimentations\n",
    "from utils import model_loading\n",
    "path = \"saved/sentimental_camembert_model.pth\"\n",
    "model = model_loading(path)\n",
    "\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "#model.to('cuda')\n",
    "#tokenizer = transformers.CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"je ne suis pas du tout satisfait de ce film!\"\n",
    "text2 = \"je suis très satisfait de ce film!\"\n",
    "text4 = \"l'acteur principal de ce film n'est pas très doué.\"\n",
    "text5 = \"j'aime pas ce film.\"\n",
    "text6 = \"Ce film m'ennuie\"\n",
    "text7 = \"Le film est excitant.\"\n",
    "text8 = \"Le film m'a fait pleuré d'ennui\"\n",
    "text9 = \"Le jeu de rôle des acteurs est super !\"\n",
    "text10 = \"Ce rôle n'est pas adapté à Morgan Freeman!\"\n",
    "text11 = \"Ce film est d'un ennui succombant.\"\n",
    "text12 = \"Thierry votre prestation n'était pas à la hauteur de mes attentes!\"\n",
    "text13 = \"La performance de Denzel lui a valu à juste titre l'oscar de l'année\"\n",
    "text14 = \"La série permet au spectateur de se laisser mener sans encombre jusqu'à la fin\"\n",
    "text15 = \"il y a quelques trous d'air dans le scénario\"\n",
    "\n",
    "#encoded_text = torch.tensor(tokenizer.encode(text, max_length=512, truncation=True))\n",
    "#encoded_text = encoded_text.unsqueeze(0).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# On GPU \n",
    "#CPU times: user 12.6 ms, sys: 4.12 ms, total: 16.7 ms\n",
    "#Wall time: 15.5 ms\n",
    "one_inference_fn(text6, model, tokenizer, device='cpu', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# On CPU\n",
    "# CPU times: user 311 ms, sys: 143 µs, total: 311 ms\n",
    "# Wall time: 64.7 ms\n",
    "one_inference_fn(text15, model, tokenizer, device='cpu', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curl -X 'POST' 'http://127.0.0.1:5000/predictions' --data-urlencode \"sentence=j'ai commencé  me rejouir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "('a', 'b') + ('c', 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences_ids</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40b8d1f1-065a-4b77-9176-77b2f4d15d3a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47bbce02-43ea-4aa8-a47c-3b92a60e8f97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae844090-0cea-44e6-a797-d62e5cc5538b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d42371c9-5095-4db9-b4be-66d6cc2e26b4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90f0cf64-aed8-42cd-b043-d0058d97c2ae</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>069fd58e-3206-4016-994b-374e60d0d52c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>379a0a03-1678-4716-aa98-bac6e52fd12b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c550b1a8-541b-4283-b9ce-1a80dcab3e30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c9352bc0-5f4e-45ab-bde6-8e92d3dca5f1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91380883-4c4e-4140-b5bc-56a7d9b6daab</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentences_ids  sentiments\n",
       "0  40b8d1f1-065a-4b77-9176-77b2f4d15d3a           1\n",
       "1  47bbce02-43ea-4aa8-a47c-3b92a60e8f97           1\n",
       "2  ae844090-0cea-44e6-a797-d62e5cc5538b           0\n",
       "3  d42371c9-5095-4db9-b4be-66d6cc2e26b4           0\n",
       "4  90f0cf64-aed8-42cd-b043-d0058d97c2ae           0\n",
       "5  069fd58e-3206-4016-994b-374e60d0d52c           1\n",
       "6  379a0a03-1678-4716-aa98-bac6e52fd12b           1\n",
       "7  c550b1a8-541b-4283-b9ce-1a80dcab3e30           1\n",
       "8  c9352bc0-5f4e-45ab-bde6-8e92d3dca5f1           1\n",
       "9  91380883-4c4e-4140-b5bc-56a7d9b6daab           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('predictions/96a52b12-e187-4e43-86e8-3fc6afdd54ad_Jan-25-2021.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
